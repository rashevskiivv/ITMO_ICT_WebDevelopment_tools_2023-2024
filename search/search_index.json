{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Practice Check out practice commit or practice1 folder. Other in lab section.","title":"Practice"},{"location":"#practice","text":"Check out practice commit or practice1 folder. Other in lab section.","title":"Practice"},{"location":"lab/","text":"Lab Structure Code models from datetime import datetime from enum import Enum from typing import Optional, List from sqlmodel import SQLModel, Field, Relationship class CategoryEnum(Enum): salary = 'salary' home = 'home' health = 'health' sports = 'sports' food = 'food' technology = 'technology' cashback = 'cashback' gifts = 'gifts' other = 'other' class OperationEnum(Enum): income = 'income' # revenue outcome = 'outcome' # expense class CategoryOperationLink(SQLModel, table=True): # many-many id: Optional[int] = Field(default=None, primary_key=True, unique=True) category_id: Optional[int] = Field( default=None, foreign_key=\"category.id\", primary_key=True ) operation_id: Optional[int] = Field( default=None, foreign_key=\"operation.id\", primary_key=True ) amount: Optional[float] = Field(default=None) class Category(SQLModel, table=True): id: Optional[int] = Field(default=None, primary_key=True) category: CategoryEnum = Field(unique=True) limit: float = Field(default=0.0) current: float = Field(default=0.0) operations: Optional[List[\"Operation\"]] = Relationship(back_populates=\"categories\", link_model=CategoryOperationLink) # many-many favourite_category: List[\"Customer\"] = Relationship(back_populates=\"favourite_category\") # 1-many # * class Operation(SQLModel, table=True): id: Optional[int] = Field(default=None, primary_key=True) operation: OperationEnum = Field(unique=True) limit: float = Field(default=0.0) alias: Optional[str] = Field(default=None, nullable=True) categories: Optional[List[Category]] = Relationship(back_populates=\"operations\", link_model=CategoryOperationLink) # many-many class User(SQLModel): username: str = Field(unique=True, index=True, nullable=False) password: str = Field(nullable=False) favourite_category_id: Optional[int] = Field(default=None, foreign_key=\"category.id\") # 1-many class Customer(User, table=True): id: Optional[int] = Field(default=None, primary_key=True) balance: float = Field(default=0.0, nullable=False) favourite_category: Optional[Category] = Relationship(back_populates=\"favourite_category\") # 1-many # * class CustomerCategory(User): favourite_category: Optional[Category] = None # * class Transaction(SQLModel, table=True): id: Optional[int] = Field(default=None, primary_key=True) date: datetime = Field(default=None, nullable=False) amount: float = Field(default=None, nullable=False) customer_id: Optional[int] = Field(default=None, foreign_key=\"customer.id\") # 1-many category_operation_link_id: Optional[int] = Field(default=None, foreign_key=\"categoryoperationlink.id\") # 1-many Customer handler (other are similar) from typing import List from fastapi import APIRouter, Depends from db import get_session from models import Customer, CustomerCategory customerRouter = APIRouter(prefix=\"/customers\", tags=[\"customer\"]) # \u043e\u0442\u0432\u0435\u0447\u0430\u0435\u0442 \u0437\u0430 swagger @customerRouter.get(\"/\", response_model=list[CustomerCategory]) async def get_customers(session=Depends(get_session)) -> List[Customer]: customers = session.query(Customer).all() return customers @customerRouter.get(\"/{username_id}\", response_model=CustomerCategory) async def get_customer(username_id: int, session=Depends(get_session)) -> Customer: customer = session.get(Customer, username_id) return customer @customerRouter.post(\"/\") async def create_customer(customer: Customer, session=Depends(get_session)): customer = Customer.validate(customer) customer.id = None session.add(customer) session.commit() session.refresh(customer) return customer @customerRouter.patch(\"/{username}\") async def update_customer(customer: Customer, username: str, session=Depends(get_session)): customer = Customer.validate(customer) customer_from_db = session.query(Customer).filter(Customer.username == username).first() if customer_from_db is None: return \"No such customer\" customer_data = customer.model_dump(exclude_unset=True) for key, value in customer_data.items(): if value is None: continue setattr(customer_from_db, key, value) session.add(customer_from_db) session.commit() session.refresh(customer_from_db) return customer_from_db @customerRouter.delete(\"/{username}\") async def delete_customer(username: str, session=Depends(get_session)): session.query(Customer).filter(Customer.username == username).delete() session.commit() return \"Deleted\" DB from sqlmodel import SQLModel, Session, create_engine from dotenv import load_dotenv import os load_dotenv('.env') db_url = os.getenv('DB_URL') print(db_url) engine = create_engine(db_url, echo=True) def init_db(): SQLModel.metadata.create_all(engine) def get_session(): with Session(engine) as session: yield session Screenshots Swagger","title":"Lab"},{"location":"lab/#lab","text":"","title":"Lab"},{"location":"lab/#structure","text":"","title":"Structure"},{"location":"lab/#code","text":"","title":"Code"},{"location":"lab/#models","text":"from datetime import datetime from enum import Enum from typing import Optional, List from sqlmodel import SQLModel, Field, Relationship class CategoryEnum(Enum): salary = 'salary' home = 'home' health = 'health' sports = 'sports' food = 'food' technology = 'technology' cashback = 'cashback' gifts = 'gifts' other = 'other' class OperationEnum(Enum): income = 'income' # revenue outcome = 'outcome' # expense class CategoryOperationLink(SQLModel, table=True): # many-many id: Optional[int] = Field(default=None, primary_key=True, unique=True) category_id: Optional[int] = Field( default=None, foreign_key=\"category.id\", primary_key=True ) operation_id: Optional[int] = Field( default=None, foreign_key=\"operation.id\", primary_key=True ) amount: Optional[float] = Field(default=None) class Category(SQLModel, table=True): id: Optional[int] = Field(default=None, primary_key=True) category: CategoryEnum = Field(unique=True) limit: float = Field(default=0.0) current: float = Field(default=0.0) operations: Optional[List[\"Operation\"]] = Relationship(back_populates=\"categories\", link_model=CategoryOperationLink) # many-many favourite_category: List[\"Customer\"] = Relationship(back_populates=\"favourite_category\") # 1-many # * class Operation(SQLModel, table=True): id: Optional[int] = Field(default=None, primary_key=True) operation: OperationEnum = Field(unique=True) limit: float = Field(default=0.0) alias: Optional[str] = Field(default=None, nullable=True) categories: Optional[List[Category]] = Relationship(back_populates=\"operations\", link_model=CategoryOperationLink) # many-many class User(SQLModel): username: str = Field(unique=True, index=True, nullable=False) password: str = Field(nullable=False) favourite_category_id: Optional[int] = Field(default=None, foreign_key=\"category.id\") # 1-many class Customer(User, table=True): id: Optional[int] = Field(default=None, primary_key=True) balance: float = Field(default=0.0, nullable=False) favourite_category: Optional[Category] = Relationship(back_populates=\"favourite_category\") # 1-many # * class CustomerCategory(User): favourite_category: Optional[Category] = None # * class Transaction(SQLModel, table=True): id: Optional[int] = Field(default=None, primary_key=True) date: datetime = Field(default=None, nullable=False) amount: float = Field(default=None, nullable=False) customer_id: Optional[int] = Field(default=None, foreign_key=\"customer.id\") # 1-many category_operation_link_id: Optional[int] = Field(default=None, foreign_key=\"categoryoperationlink.id\") # 1-many","title":"models"},{"location":"lab/#customer-handler-other-are-similar","text":"from typing import List from fastapi import APIRouter, Depends from db import get_session from models import Customer, CustomerCategory customerRouter = APIRouter(prefix=\"/customers\", tags=[\"customer\"]) # \u043e\u0442\u0432\u0435\u0447\u0430\u0435\u0442 \u0437\u0430 swagger @customerRouter.get(\"/\", response_model=list[CustomerCategory]) async def get_customers(session=Depends(get_session)) -> List[Customer]: customers = session.query(Customer).all() return customers @customerRouter.get(\"/{username_id}\", response_model=CustomerCategory) async def get_customer(username_id: int, session=Depends(get_session)) -> Customer: customer = session.get(Customer, username_id) return customer @customerRouter.post(\"/\") async def create_customer(customer: Customer, session=Depends(get_session)): customer = Customer.validate(customer) customer.id = None session.add(customer) session.commit() session.refresh(customer) return customer @customerRouter.patch(\"/{username}\") async def update_customer(customer: Customer, username: str, session=Depends(get_session)): customer = Customer.validate(customer) customer_from_db = session.query(Customer).filter(Customer.username == username).first() if customer_from_db is None: return \"No such customer\" customer_data = customer.model_dump(exclude_unset=True) for key, value in customer_data.items(): if value is None: continue setattr(customer_from_db, key, value) session.add(customer_from_db) session.commit() session.refresh(customer_from_db) return customer_from_db @customerRouter.delete(\"/{username}\") async def delete_customer(username: str, session=Depends(get_session)): session.query(Customer).filter(Customer.username == username).delete() session.commit() return \"Deleted\"","title":"Customer handler (other are similar)"},{"location":"lab/#db","text":"from sqlmodel import SQLModel, Session, create_engine from dotenv import load_dotenv import os load_dotenv('.env') db_url = os.getenv('DB_URL') print(db_url) engine = create_engine(db_url, echo=True) def init_db(): SQLModel.metadata.create_all(engine) def get_session(): with Session(engine) as session: yield session","title":"DB"},{"location":"lab/#screenshots","text":"","title":"Screenshots"},{"location":"lab/#swagger","text":"","title":"Swagger"},{"location":"lab2/","text":"Lab 2 \u041f\u043e\u0434\u044b\u0442\u043e\u0433: \u0441\u043e\u0437\u0434\u0430\u043d\u0438\u0435 \u043f\u0440\u043e\u0446\u0435\u0441\u0441\u0430 \u0434\u043e\u0440\u043e\u0436\u0435 \u0441\u043e\u0437\u0434\u0430\u043d\u0438\u044f \u043f\u043e\u0442\u043e\u043a\u0430, \u0441\u043e\u0437\u0434\u0430\u043d\u0438\u0435 \u043f\u043e\u0442\u043e\u043a\u0430 \u0434\u043e\u0440\u043e\u0436\u0435 \u0441\u043e\u0437\u0434\u0430\u043d\u0438\u044f \u0440\u0443\u0442\u0438\u043d\u044b. \u0412\u0440\u0435\u043c\u044f \u0432\u044b\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u044f \u0432 \u0441\u0440\u0435\u0434\u043d\u0435\u043c \u0443 async < threading < multiprocessing. Code + screenshots async1.py \u0421\u043e\u0437\u0434\u0430\u0435\u043c \u043d\u0443\u0436\u043d\u043e\u0435 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e (\u043a\u043e/\u0433\u043e)\u0440\u0443\u0442\u0438\u043d \u0438 \u0434\u0435\u043b\u0438\u043c 1_000_000 \u043d\u0430 \u0438\u0445 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e. \u041a\u0430\u0436\u0434\u0430\u044f \u0435\u0434\u0438\u043d\u0438\u0446\u0430 \u0432\u044b\u043f\u043e\u043b\u043d\u0438\u0442 \u0444\u0443\u043d\u043a\u0446\u0438\u044e, \u043a\u043e\u0442\u043e\u0440\u0430\u044f \u0441\u0443\u043c\u043c\u0438\u0440\u0443\u0435\u0442 \u0432\u0441\u0435 \u0442\u043e\u0447\u043a\u0438 \u0434\u0430\u043d\u043d\u043e\u0433\u043e \u043e\u0442\u0440\u0435\u0437\u043a\u0430 \u0438 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442 \u0434\u043e\u0431\u0430\u0432\u0438\u0442 \u0432 \u043b\u0438\u0441\u0442. \u041f\u043e\u0441\u043b\u0435 \u0432\u044b\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u044f \u0441\u0443\u043c\u043c\u0438\u0440\u0443\u044e\u0442\u0441\u044f \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u044b \u0438 \u0432\u044b\u0432\u043e\u0434\u0438\u0442\u0441\u044f \u0432 \u043a\u043e\u043d\u0441\u043e\u043b\u0438 \u0432\u043c\u0435\u0441\u0442\u0435 \u0441 \u0432\u0440\u0435\u043c\u0435\u043d\u0435\u043c \u0432\u044b\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u044f. import asyncio from time import time async def calculate_sum(start, end, index): print(f\"started {index}\") s = sum(range(start, end + 1)) print(f\"finished {index}\") return s async def main(task_count): numbers_per_task = 1_000_000 // task_count tasks = list() start_time = time() for i in range(task_count): start = i * numbers_per_task + 1 end = start + numbers_per_task - 1 tasks.append(calculate_sum(start, end, i)) results = await asyncio.gather(*tasks) total_sum = sum(results) end_time = time() return total_sum, end_time - start_time if __name__ == \"__main__\": result, time = asyncio.run(main(4)) print(f\"Result of execution 'async': {result}\") print(f\"Time of execution 'async': {time} seconds\") multiprocessing1.py \u0421\u043e\u0437\u0434\u0430\u0435\u043c \u043d\u0443\u0436\u043d\u043e\u0435 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043f\u0440\u043e\u0446\u0435\u0441\u0441\u043e\u0432 \u0438 \u0434\u0435\u043b\u0438\u043c 1_000_000 \u043d\u0430 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043f\u0440\u043e\u0446\u0435\u0441\u0441\u043e\u0432. \u041a\u0430\u0436\u0434\u044b\u0439 \u043f\u0440\u043e\u0446\u0435\u0441\u0441 \u0438\u043c\u0435\u0435\u0442 \u0441\u0432\u043e\u0438 \u0440\u0435\u0441\u0443\u0440\u0441\u044b, \u0432 \u043e\u0442\u043b\u0438\u0447\u0438\u0435 \u043e\u0442 \u043f\u043e\u0442\u043e\u043a\u043e\u0432 - \u043d\u0443\u0436\u043d\u043e \u0441\u043e\u0437\u0434\u0430\u0442\u044c \u043e\u0431\u0449\u0438\u0439 \u043e\u0431\u044a\u0435\u043a\u0442 Queue, \u043a\u043e\u0442\u043e\u0440\u044b\u0439 \u0445\u0440\u0430\u043d\u0438\u0442 \u0432\u0441\u0435 \u0441\u0443\u043c\u043c\u044b. \u041f\u0440\u043e\u0446\u0435\u0441\u0441 \u0432\u044b\u043f\u043e\u043b\u043d\u0438\u0442 \u0444\u0443\u043d\u043a\u0446\u0438\u044e, \u043a\u043e\u0442\u043e\u0440\u0430\u044f \u0441\u0443\u043c\u043c\u0438\u0440\u0443\u0435\u0442 \u0432\u0441\u0435 \u0442\u043e\u0447\u043a\u0438 \u0434\u0430\u043d\u043d\u043e\u0433\u043e \u043e\u0442\u0440\u0435\u0437\u043a\u0430 \u0438 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442 \u0434\u043e\u0431\u0430\u0432\u0438\u0442 \u0432 \u043e\u0447\u0435\u0440\u0435\u0434\u044c. \u041f\u043e\u0441\u043b\u0435 \u0432\u044b\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u044f \u0432\u0441\u0435\u0445 \u043f\u0440\u043e\u0446\u0435\u0441\u0441\u043e\u0432 \u0441\u0443\u043c\u043c\u0438\u0440\u0443\u044e\u0442\u0441\u044f \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u044b \u0438 \u0432\u044b\u0432\u043e\u0434\u0438\u0442\u0441\u044f \u0432 \u043a\u043e\u043d\u0441\u043e\u043b\u0438 \u0432\u043c\u0435\u0441\u0442\u0435 \u0441 \u0432\u0440\u0435\u043c\u0435\u043d\u0435\u043c \u0432\u044b\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u044f. from multiprocessing import Process, Queue from time import time def calculate_sum(start, end, result, index): print(f\"started {index}\") result.put(sum(range(start, end + 1))) print(f\"finished {index}\") def main(process_count): numbers_per_process = 1_000_000 // process_count processes = list() q = Queue() start_time = time() for i in range(process_count): start = i * numbers_per_process + 1 end = start + numbers_per_process - 1 p = Process(target=calculate_sum, args=(start, end, q, i)) processes.append(p) p.start() for p in processes: p.join() result = 0 while not q.empty(): result += q.get() end_time = time() return result, end_time - start_time if __name__ == \"__main__\": result, time = main(4) print(f\"Result of execution 'multiprocessing': {result}\") print(f\"Time of execution 'multiprocessing': {time} seconds\") threading1.py \u0421\u043e\u0437\u0434\u0430\u0435\u043c \u043d\u0443\u0436\u043d\u043e\u0435 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043f\u043e\u0442\u043e\u043a\u043e\u0432 \u0438 \u0434\u0435\u043b\u0438\u043c 1_000_000 \u043d\u0430 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043f\u043e\u0442\u043e\u043a\u043e\u0432. \u041a\u0430\u0436\u0434\u044b\u0439 \u043f\u043e\u0442\u043e\u043a \u0432\u044b\u043f\u043e\u043b\u043d\u0438\u0442 \u0444\u0443\u043d\u043a\u0446\u0438\u044e, \u043a\u043e\u0442\u043e\u0440\u0430\u044f \u0441\u0443\u043c\u043c\u0438\u0440\u0443\u0435\u0442 \u0432\u0441\u0435 \u0442\u043e\u0447\u043a\u0438 \u0434\u0430\u043d\u043d\u043e\u0433\u043e \u043e\u0442\u0440\u0435\u0437\u043a\u0430 \u0438 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442 \u0434\u043e\u0431\u0430\u0432\u0438\u0442 \u0432 \u043b\u0438\u0441\u0442. \u041f\u043e\u0441\u043b\u0435 \u0432\u044b\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u044f \u0432\u0441\u0435\u0445 \u043f\u043e\u0442\u043e\u043a\u043e\u0432 \u0441\u0443\u043c\u043c\u0438\u0440\u0443\u044e\u0442\u0441\u044f \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u044b \u0438 \u0432\u044b\u0432\u043e\u0434\u0438\u0442\u0441\u044f \u0432 \u043a\u043e\u043d\u0441\u043e\u043b\u0438 \u0432\u043c\u0435\u0441\u0442\u0435 \u0441 \u0432\u0440\u0435\u043c\u0435\u043d\u0435\u043c \u0432\u044b\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u044f. import threading from time import time def calculate_sum(start, end, result, index): print(f\"started {index}\") result[index] = sum(range(start, end + 1)) print(f\"finished {index}\") def main(thread_count): numbers_per_thread = 1_000_000 // thread_count threads = list() results = [0] * thread_count start_time = time() for i in range(thread_count): start = i * numbers_per_thread + 1 end = start + numbers_per_thread - 1 t = threading.Thread(target=calculate_sum, args=(start, end, results, i)) threads.append(t) t.start() for t in threads: t.join() total_sum = sum(results) end_time = time() return total_sum, end_time - start_time if __name__ == \"__main__\": result, time = main(4) print(f\"Result of execution 'threading': {result}\") print(f\"Time of execution 'threading': {time} seconds\") async2.py import asyncio import time import aiohttp from bs4 import BeautifulSoup from connection import DB from urls import URLs async def parse_and_save_async(url, con): try: async with aiohttp.ClientSession(connector=aiohttp.TCPConnector(ssl=False)) as session: async with session.get(url) as response: page = await response.text() soup = BeautifulSoup(page, 'html.parser') print(soup.find('title').text) # \u0441\u043e\u0445\u0440\u0430\u043d\u044f\u0442\u044c \u0437\u0430\u0433\u043e\u043b\u043e\u0432\u043e\u043a \u0441\u0442\u0440\u0430\u043d\u0438\u0446\u044b \u0432 \u0431\u0430\u0437\u0443 \u0434\u0430\u043d\u043d\u044b\u0445 \u043f\u043e \u043c\u043d\u0435 \u0431\u0435\u0441\u043f\u043e\u043b\u0435\u0437\u043d\u043e # \u0442.\u043a. \u043d\u0430\u0433\u0440\u0443\u0437\u043a\u0438 0 \u043f\u043e\u043b\u0435\u0437\u043d\u043e\u0439, \u043f\u043e\u044d\u0442\u043e\u043c\u0443 \u0432\u044b\u0432\u043e\u0436\u0443 \u0432 \u043a\u043e\u043d\u0441\u043e\u043b\u044c prs = soup.find_all('div', class_='Box-row Box-row--focus-gray p-0 mt-0 js-navigation-item js-issue-row') for pr in prs: title = (pr.find('a', class_='Link--primary v-align-middle no-underline h4 js-navigation-open markdown-title'). text) span_text = pr.find('span', class_='opened-by').text.split() date = span_text[2] + ' ' + span_text[3][:-1] + ' ' + span_text[4] author = span_text[6] with con.cursor() as cursor: cursor.execute(DB.INSERT_SQL, (title, date, author)) con.commit() except Exception as e: print(\"Exception caught: \", e) async def process_url_list_async(url_list, con): tasks = [] for url in url_list: task = asyncio.create_task(parse_and_save_async(url, con)) tasks.append(task) await asyncio.gather(*tasks) async def main(): count_for_1_thread = 2 urls_for_1_thread = [URLs[i:i + count_for_1_thread] for i in range(0, len(URLs), count_for_1_thread)] con = DB.connect() await asyncio.gather(*(process_url_list_async(urls, con) for urls in urls_for_1_thread)) con.close() if __name__ == '__main__': start_time = time.time() asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy()) asyncio.run(main()) end_time = time.time() print(f\"Time of execution 'async': {end_time - start_time} seconds\") multiprocessing2.py import multiprocessing import time import requests from bs4 import BeautifulSoup from connection import DB from urls import URLs def parse_and_save_multiprocessing(url): con = DB.connect() try: page = requests.get(url) soup = BeautifulSoup(page.text, 'html.parser') print(soup.find('title').text) # \u0441\u043e\u0445\u0440\u0430\u043d\u044f\u0442\u044c \u0437\u0430\u0433\u043e\u043b\u043e\u0432\u043e\u043a \u0441\u0442\u0440\u0430\u043d\u0438\u0446\u044b \u0432 \u0431\u0430\u0437\u0443 \u0434\u0430\u043d\u043d\u044b\u0445 \u043f\u043e \u043c\u043d\u0435 \u0431\u0435\u0441\u043f\u043e\u043b\u0435\u0437\u043d\u043e # \u0442.\u043a. \u043d\u0430\u0433\u0440\u0443\u0437\u043a\u0438 0 \u043f\u043e\u043b\u0435\u0437\u043d\u043e\u0439, \u043f\u043e\u044d\u0442\u043e\u043c\u0443 \u0432\u044b\u0432\u043e\u0436\u0443 \u0432 \u043a\u043e\u043d\u0441\u043e\u043b\u044c prs = soup.find_all('div', class_='Box-row Box-row--focus-gray p-0 mt-0 js-navigation-item js-issue-row') for pr in prs: title = (pr.find('a', class_='Link--primary v-align-middle no-underline h4 js-navigation-open markdown-title'). text) span_text = pr.find('span', class_='opened-by').text.split() date = span_text[2] + ' ' + span_text[3][:-1] + ' ' + span_text[4] author = span_text[6] with con.cursor() as cursor: cursor.execute(DB.INSERT_SQL, (title, date, author)) con.commit() except Exception as e: print(\"Exception caught: \", e) finally: con.close() def process_url_list_multiprocessing(url_list): for url in url_list: parse_and_save_multiprocessing(url) def main_multiprocessing(): count_for_1_thread = 2 urls_for_1_thread = [URLs[i:i + count_for_1_thread] for i in range(0, len(URLs), count_for_1_thread)] processes = [] for urls in urls_for_1_thread: process = multiprocessing.Process(target=process_url_list_multiprocessing, args=(urls,)) # make a tuple processes.append(process) process.start() for process in processes: process.join() if __name__ == '__main__': start_time = time.time() main_multiprocessing() end_time = time.time() print(f\"Time of execution 'multiprocessing': {end_time - start_time} seconds\") threading2.py import threading import time from connection import DB import requests from bs4 import BeautifulSoup from urls import URLs def parse_and_save_threading(url, con): try: page = requests.get(url) soup = BeautifulSoup(page.text, 'html.parser') print(soup.find('title').text) # \u0441\u043e\u0445\u0440\u0430\u043d\u044f\u0442\u044c \u0437\u0430\u0433\u043e\u043b\u043e\u0432\u043e\u043a \u0441\u0442\u0440\u0430\u043d\u0438\u0446\u044b \u0432 \u0431\u0430\u0437\u0443 \u0434\u0430\u043d\u043d\u044b\u0445 \u043f\u043e \u043c\u043d\u0435 \u0431\u0435\u0441\u043f\u043e\u043b\u0435\u0437\u043d\u043e # \u0442.\u043a. \u043d\u0430\u0433\u0440\u0443\u0437\u043a\u0438 0 \u043f\u043e\u043b\u0435\u0437\u043d\u043e\u0439, \u043f\u043e\u044d\u0442\u043e\u043c\u0443 \u0432\u044b\u0432\u043e\u0436\u0443 \u0432 \u043a\u043e\u043d\u0441\u043e\u043b\u044c prs = soup.find_all('div', class_='Box-row Box-row--focus-gray p-0 mt-0 js-navigation-item js-issue-row') for pr in prs: title = (pr.find('a', class_='Link--primary v-align-middle no-underline h4 js-navigation-open markdown-title'). text) span_text = pr.find('span', class_='opened-by').text.split() date = span_text[2] + ' ' + span_text[3][:-1] + ' ' + span_text[4] author = span_text[6] with con.cursor() as cursor: cursor.execute(DB.INSERT_SQL, (title, date, author)) con.commit() except Exception as e: print(\"Exception caught: \", e) def process_url_list_threading(url_list, con): for url in url_list: parse_and_save_threading(url, con) def main_threading(): count_for_1_thread = 2 urls_for_1_thread = [URLs[i:i + count_for_1_thread] for i in range(0, len(URLs), count_for_1_thread)] con = DB.connect() threads = [] for urls in urls_for_1_thread: thread = threading.Thread(target=process_url_list_threading, args=(urls, con)) threads.append(thread) thread.start() for thread in threads: thread.join() con.close() if __name__ == '__main__': start_time = time.time() main_threading() end_time = time.time() print(f\"Time of execution 'threading': {end_time - start_time} seconds\") urls.py URLs = [ 'https://github.com/TonikX/ITMO_ICT_WebDevelopment_tools_2023-2024/pulls?page=1&q=is%3Apr+is%3Aopen', 'https://github.com/TonikX/ITMO_ICT_WebDevelopment_tools_2023-2024/pulls?page=2&q=is%3Apr+is%3Aopen', 'https://github.com/TonikX/ITMO_ICT_WebDevelopment_tools_2023-2024/pulls?page=3&q=is%3Apr+is%3Aopen', 'https://github.com/TonikX/ITMO_ICT_WebDevelopment_2022-2023/pulls?page=1&q=is%3Apr+is%3Aopen', 'https://github.com/TonikX/ITMO_ICT_WebDevelopment_2022-2023/pulls?page=2&q=is%3Apr+is%3Aopen', 'https://github.com/TonikX/ITMO_ICT_WebDevelopment_2022-2023/pulls?page=3&q=is%3Apr+is%3Aopen', ] connection.py import psycopg2 class DB: INSERT_SQL = \"\"\"insert into public.prs(title, date, author) values (%s, %s, %s);\"\"\" @staticmethod def connect(): con = psycopg2.connect( dbname=\"web_tools_db\", user=\"postgres\", password=\"postgres\", host=\"localhost\", port=\"5432\" ) return con","title":"Lab 2"},{"location":"lab2/#lab-2","text":"\u041f\u043e\u0434\u044b\u0442\u043e\u0433: \u0441\u043e\u0437\u0434\u0430\u043d\u0438\u0435 \u043f\u0440\u043e\u0446\u0435\u0441\u0441\u0430 \u0434\u043e\u0440\u043e\u0436\u0435 \u0441\u043e\u0437\u0434\u0430\u043d\u0438\u044f \u043f\u043e\u0442\u043e\u043a\u0430, \u0441\u043e\u0437\u0434\u0430\u043d\u0438\u0435 \u043f\u043e\u0442\u043e\u043a\u0430 \u0434\u043e\u0440\u043e\u0436\u0435 \u0441\u043e\u0437\u0434\u0430\u043d\u0438\u044f \u0440\u0443\u0442\u0438\u043d\u044b. \u0412\u0440\u0435\u043c\u044f \u0432\u044b\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u044f \u0432 \u0441\u0440\u0435\u0434\u043d\u0435\u043c \u0443 async < threading < multiprocessing.","title":"Lab 2"},{"location":"lab2/#code-screenshots","text":"","title":"Code + screenshots"},{"location":"lab2/#async1py","text":"\u0421\u043e\u0437\u0434\u0430\u0435\u043c \u043d\u0443\u0436\u043d\u043e\u0435 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e (\u043a\u043e/\u0433\u043e)\u0440\u0443\u0442\u0438\u043d \u0438 \u0434\u0435\u043b\u0438\u043c 1_000_000 \u043d\u0430 \u0438\u0445 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e. \u041a\u0430\u0436\u0434\u0430\u044f \u0435\u0434\u0438\u043d\u0438\u0446\u0430 \u0432\u044b\u043f\u043e\u043b\u043d\u0438\u0442 \u0444\u0443\u043d\u043a\u0446\u0438\u044e, \u043a\u043e\u0442\u043e\u0440\u0430\u044f \u0441\u0443\u043c\u043c\u0438\u0440\u0443\u0435\u0442 \u0432\u0441\u0435 \u0442\u043e\u0447\u043a\u0438 \u0434\u0430\u043d\u043d\u043e\u0433\u043e \u043e\u0442\u0440\u0435\u0437\u043a\u0430 \u0438 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442 \u0434\u043e\u0431\u0430\u0432\u0438\u0442 \u0432 \u043b\u0438\u0441\u0442. \u041f\u043e\u0441\u043b\u0435 \u0432\u044b\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u044f \u0441\u0443\u043c\u043c\u0438\u0440\u0443\u044e\u0442\u0441\u044f \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u044b \u0438 \u0432\u044b\u0432\u043e\u0434\u0438\u0442\u0441\u044f \u0432 \u043a\u043e\u043d\u0441\u043e\u043b\u0438 \u0432\u043c\u0435\u0441\u0442\u0435 \u0441 \u0432\u0440\u0435\u043c\u0435\u043d\u0435\u043c \u0432\u044b\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u044f. import asyncio from time import time async def calculate_sum(start, end, index): print(f\"started {index}\") s = sum(range(start, end + 1)) print(f\"finished {index}\") return s async def main(task_count): numbers_per_task = 1_000_000 // task_count tasks = list() start_time = time() for i in range(task_count): start = i * numbers_per_task + 1 end = start + numbers_per_task - 1 tasks.append(calculate_sum(start, end, i)) results = await asyncio.gather(*tasks) total_sum = sum(results) end_time = time() return total_sum, end_time - start_time if __name__ == \"__main__\": result, time = asyncio.run(main(4)) print(f\"Result of execution 'async': {result}\") print(f\"Time of execution 'async': {time} seconds\")","title":"async1.py"},{"location":"lab2/#multiprocessing1py","text":"\u0421\u043e\u0437\u0434\u0430\u0435\u043c \u043d\u0443\u0436\u043d\u043e\u0435 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043f\u0440\u043e\u0446\u0435\u0441\u0441\u043e\u0432 \u0438 \u0434\u0435\u043b\u0438\u043c 1_000_000 \u043d\u0430 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043f\u0440\u043e\u0446\u0435\u0441\u0441\u043e\u0432. \u041a\u0430\u0436\u0434\u044b\u0439 \u043f\u0440\u043e\u0446\u0435\u0441\u0441 \u0438\u043c\u0435\u0435\u0442 \u0441\u0432\u043e\u0438 \u0440\u0435\u0441\u0443\u0440\u0441\u044b, \u0432 \u043e\u0442\u043b\u0438\u0447\u0438\u0435 \u043e\u0442 \u043f\u043e\u0442\u043e\u043a\u043e\u0432 - \u043d\u0443\u0436\u043d\u043e \u0441\u043e\u0437\u0434\u0430\u0442\u044c \u043e\u0431\u0449\u0438\u0439 \u043e\u0431\u044a\u0435\u043a\u0442 Queue, \u043a\u043e\u0442\u043e\u0440\u044b\u0439 \u0445\u0440\u0430\u043d\u0438\u0442 \u0432\u0441\u0435 \u0441\u0443\u043c\u043c\u044b. \u041f\u0440\u043e\u0446\u0435\u0441\u0441 \u0432\u044b\u043f\u043e\u043b\u043d\u0438\u0442 \u0444\u0443\u043d\u043a\u0446\u0438\u044e, \u043a\u043e\u0442\u043e\u0440\u0430\u044f \u0441\u0443\u043c\u043c\u0438\u0440\u0443\u0435\u0442 \u0432\u0441\u0435 \u0442\u043e\u0447\u043a\u0438 \u0434\u0430\u043d\u043d\u043e\u0433\u043e \u043e\u0442\u0440\u0435\u0437\u043a\u0430 \u0438 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442 \u0434\u043e\u0431\u0430\u0432\u0438\u0442 \u0432 \u043e\u0447\u0435\u0440\u0435\u0434\u044c. \u041f\u043e\u0441\u043b\u0435 \u0432\u044b\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u044f \u0432\u0441\u0435\u0445 \u043f\u0440\u043e\u0446\u0435\u0441\u0441\u043e\u0432 \u0441\u0443\u043c\u043c\u0438\u0440\u0443\u044e\u0442\u0441\u044f \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u044b \u0438 \u0432\u044b\u0432\u043e\u0434\u0438\u0442\u0441\u044f \u0432 \u043a\u043e\u043d\u0441\u043e\u043b\u0438 \u0432\u043c\u0435\u0441\u0442\u0435 \u0441 \u0432\u0440\u0435\u043c\u0435\u043d\u0435\u043c \u0432\u044b\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u044f. from multiprocessing import Process, Queue from time import time def calculate_sum(start, end, result, index): print(f\"started {index}\") result.put(sum(range(start, end + 1))) print(f\"finished {index}\") def main(process_count): numbers_per_process = 1_000_000 // process_count processes = list() q = Queue() start_time = time() for i in range(process_count): start = i * numbers_per_process + 1 end = start + numbers_per_process - 1 p = Process(target=calculate_sum, args=(start, end, q, i)) processes.append(p) p.start() for p in processes: p.join() result = 0 while not q.empty(): result += q.get() end_time = time() return result, end_time - start_time if __name__ == \"__main__\": result, time = main(4) print(f\"Result of execution 'multiprocessing': {result}\") print(f\"Time of execution 'multiprocessing': {time} seconds\")","title":"multiprocessing1.py"},{"location":"lab2/#threading1py","text":"\u0421\u043e\u0437\u0434\u0430\u0435\u043c \u043d\u0443\u0436\u043d\u043e\u0435 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043f\u043e\u0442\u043e\u043a\u043e\u0432 \u0438 \u0434\u0435\u043b\u0438\u043c 1_000_000 \u043d\u0430 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043f\u043e\u0442\u043e\u043a\u043e\u0432. \u041a\u0430\u0436\u0434\u044b\u0439 \u043f\u043e\u0442\u043e\u043a \u0432\u044b\u043f\u043e\u043b\u043d\u0438\u0442 \u0444\u0443\u043d\u043a\u0446\u0438\u044e, \u043a\u043e\u0442\u043e\u0440\u0430\u044f \u0441\u0443\u043c\u043c\u0438\u0440\u0443\u0435\u0442 \u0432\u0441\u0435 \u0442\u043e\u0447\u043a\u0438 \u0434\u0430\u043d\u043d\u043e\u0433\u043e \u043e\u0442\u0440\u0435\u0437\u043a\u0430 \u0438 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442 \u0434\u043e\u0431\u0430\u0432\u0438\u0442 \u0432 \u043b\u0438\u0441\u0442. \u041f\u043e\u0441\u043b\u0435 \u0432\u044b\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u044f \u0432\u0441\u0435\u0445 \u043f\u043e\u0442\u043e\u043a\u043e\u0432 \u0441\u0443\u043c\u043c\u0438\u0440\u0443\u044e\u0442\u0441\u044f \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u044b \u0438 \u0432\u044b\u0432\u043e\u0434\u0438\u0442\u0441\u044f \u0432 \u043a\u043e\u043d\u0441\u043e\u043b\u0438 \u0432\u043c\u0435\u0441\u0442\u0435 \u0441 \u0432\u0440\u0435\u043c\u0435\u043d\u0435\u043c \u0432\u044b\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u044f. import threading from time import time def calculate_sum(start, end, result, index): print(f\"started {index}\") result[index] = sum(range(start, end + 1)) print(f\"finished {index}\") def main(thread_count): numbers_per_thread = 1_000_000 // thread_count threads = list() results = [0] * thread_count start_time = time() for i in range(thread_count): start = i * numbers_per_thread + 1 end = start + numbers_per_thread - 1 t = threading.Thread(target=calculate_sum, args=(start, end, results, i)) threads.append(t) t.start() for t in threads: t.join() total_sum = sum(results) end_time = time() return total_sum, end_time - start_time if __name__ == \"__main__\": result, time = main(4) print(f\"Result of execution 'threading': {result}\") print(f\"Time of execution 'threading': {time} seconds\")","title":"threading1.py"},{"location":"lab2/#async2py","text":"import asyncio import time import aiohttp from bs4 import BeautifulSoup from connection import DB from urls import URLs async def parse_and_save_async(url, con): try: async with aiohttp.ClientSession(connector=aiohttp.TCPConnector(ssl=False)) as session: async with session.get(url) as response: page = await response.text() soup = BeautifulSoup(page, 'html.parser') print(soup.find('title').text) # \u0441\u043e\u0445\u0440\u0430\u043d\u044f\u0442\u044c \u0437\u0430\u0433\u043e\u043b\u043e\u0432\u043e\u043a \u0441\u0442\u0440\u0430\u043d\u0438\u0446\u044b \u0432 \u0431\u0430\u0437\u0443 \u0434\u0430\u043d\u043d\u044b\u0445 \u043f\u043e \u043c\u043d\u0435 \u0431\u0435\u0441\u043f\u043e\u043b\u0435\u0437\u043d\u043e # \u0442.\u043a. \u043d\u0430\u0433\u0440\u0443\u0437\u043a\u0438 0 \u043f\u043e\u043b\u0435\u0437\u043d\u043e\u0439, \u043f\u043e\u044d\u0442\u043e\u043c\u0443 \u0432\u044b\u0432\u043e\u0436\u0443 \u0432 \u043a\u043e\u043d\u0441\u043e\u043b\u044c prs = soup.find_all('div', class_='Box-row Box-row--focus-gray p-0 mt-0 js-navigation-item js-issue-row') for pr in prs: title = (pr.find('a', class_='Link--primary v-align-middle no-underline h4 js-navigation-open markdown-title'). text) span_text = pr.find('span', class_='opened-by').text.split() date = span_text[2] + ' ' + span_text[3][:-1] + ' ' + span_text[4] author = span_text[6] with con.cursor() as cursor: cursor.execute(DB.INSERT_SQL, (title, date, author)) con.commit() except Exception as e: print(\"Exception caught: \", e) async def process_url_list_async(url_list, con): tasks = [] for url in url_list: task = asyncio.create_task(parse_and_save_async(url, con)) tasks.append(task) await asyncio.gather(*tasks) async def main(): count_for_1_thread = 2 urls_for_1_thread = [URLs[i:i + count_for_1_thread] for i in range(0, len(URLs), count_for_1_thread)] con = DB.connect() await asyncio.gather(*(process_url_list_async(urls, con) for urls in urls_for_1_thread)) con.close() if __name__ == '__main__': start_time = time.time() asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy()) asyncio.run(main()) end_time = time.time() print(f\"Time of execution 'async': {end_time - start_time} seconds\")","title":"async2.py"},{"location":"lab2/#multiprocessing2py","text":"import multiprocessing import time import requests from bs4 import BeautifulSoup from connection import DB from urls import URLs def parse_and_save_multiprocessing(url): con = DB.connect() try: page = requests.get(url) soup = BeautifulSoup(page.text, 'html.parser') print(soup.find('title').text) # \u0441\u043e\u0445\u0440\u0430\u043d\u044f\u0442\u044c \u0437\u0430\u0433\u043e\u043b\u043e\u0432\u043e\u043a \u0441\u0442\u0440\u0430\u043d\u0438\u0446\u044b \u0432 \u0431\u0430\u0437\u0443 \u0434\u0430\u043d\u043d\u044b\u0445 \u043f\u043e \u043c\u043d\u0435 \u0431\u0435\u0441\u043f\u043e\u043b\u0435\u0437\u043d\u043e # \u0442.\u043a. \u043d\u0430\u0433\u0440\u0443\u0437\u043a\u0438 0 \u043f\u043e\u043b\u0435\u0437\u043d\u043e\u0439, \u043f\u043e\u044d\u0442\u043e\u043c\u0443 \u0432\u044b\u0432\u043e\u0436\u0443 \u0432 \u043a\u043e\u043d\u0441\u043e\u043b\u044c prs = soup.find_all('div', class_='Box-row Box-row--focus-gray p-0 mt-0 js-navigation-item js-issue-row') for pr in prs: title = (pr.find('a', class_='Link--primary v-align-middle no-underline h4 js-navigation-open markdown-title'). text) span_text = pr.find('span', class_='opened-by').text.split() date = span_text[2] + ' ' + span_text[3][:-1] + ' ' + span_text[4] author = span_text[6] with con.cursor() as cursor: cursor.execute(DB.INSERT_SQL, (title, date, author)) con.commit() except Exception as e: print(\"Exception caught: \", e) finally: con.close() def process_url_list_multiprocessing(url_list): for url in url_list: parse_and_save_multiprocessing(url) def main_multiprocessing(): count_for_1_thread = 2 urls_for_1_thread = [URLs[i:i + count_for_1_thread] for i in range(0, len(URLs), count_for_1_thread)] processes = [] for urls in urls_for_1_thread: process = multiprocessing.Process(target=process_url_list_multiprocessing, args=(urls,)) # make a tuple processes.append(process) process.start() for process in processes: process.join() if __name__ == '__main__': start_time = time.time() main_multiprocessing() end_time = time.time() print(f\"Time of execution 'multiprocessing': {end_time - start_time} seconds\")","title":"multiprocessing2.py"},{"location":"lab2/#threading2py","text":"import threading import time from connection import DB import requests from bs4 import BeautifulSoup from urls import URLs def parse_and_save_threading(url, con): try: page = requests.get(url) soup = BeautifulSoup(page.text, 'html.parser') print(soup.find('title').text) # \u0441\u043e\u0445\u0440\u0430\u043d\u044f\u0442\u044c \u0437\u0430\u0433\u043e\u043b\u043e\u0432\u043e\u043a \u0441\u0442\u0440\u0430\u043d\u0438\u0446\u044b \u0432 \u0431\u0430\u0437\u0443 \u0434\u0430\u043d\u043d\u044b\u0445 \u043f\u043e \u043c\u043d\u0435 \u0431\u0435\u0441\u043f\u043e\u043b\u0435\u0437\u043d\u043e # \u0442.\u043a. \u043d\u0430\u0433\u0440\u0443\u0437\u043a\u0438 0 \u043f\u043e\u043b\u0435\u0437\u043d\u043e\u0439, \u043f\u043e\u044d\u0442\u043e\u043c\u0443 \u0432\u044b\u0432\u043e\u0436\u0443 \u0432 \u043a\u043e\u043d\u0441\u043e\u043b\u044c prs = soup.find_all('div', class_='Box-row Box-row--focus-gray p-0 mt-0 js-navigation-item js-issue-row') for pr in prs: title = (pr.find('a', class_='Link--primary v-align-middle no-underline h4 js-navigation-open markdown-title'). text) span_text = pr.find('span', class_='opened-by').text.split() date = span_text[2] + ' ' + span_text[3][:-1] + ' ' + span_text[4] author = span_text[6] with con.cursor() as cursor: cursor.execute(DB.INSERT_SQL, (title, date, author)) con.commit() except Exception as e: print(\"Exception caught: \", e) def process_url_list_threading(url_list, con): for url in url_list: parse_and_save_threading(url, con) def main_threading(): count_for_1_thread = 2 urls_for_1_thread = [URLs[i:i + count_for_1_thread] for i in range(0, len(URLs), count_for_1_thread)] con = DB.connect() threads = [] for urls in urls_for_1_thread: thread = threading.Thread(target=process_url_list_threading, args=(urls, con)) threads.append(thread) thread.start() for thread in threads: thread.join() con.close() if __name__ == '__main__': start_time = time.time() main_threading() end_time = time.time() print(f\"Time of execution 'threading': {end_time - start_time} seconds\")","title":"threading2.py"},{"location":"lab2/#urlspy","text":"URLs = [ 'https://github.com/TonikX/ITMO_ICT_WebDevelopment_tools_2023-2024/pulls?page=1&q=is%3Apr+is%3Aopen', 'https://github.com/TonikX/ITMO_ICT_WebDevelopment_tools_2023-2024/pulls?page=2&q=is%3Apr+is%3Aopen', 'https://github.com/TonikX/ITMO_ICT_WebDevelopment_tools_2023-2024/pulls?page=3&q=is%3Apr+is%3Aopen', 'https://github.com/TonikX/ITMO_ICT_WebDevelopment_2022-2023/pulls?page=1&q=is%3Apr+is%3Aopen', 'https://github.com/TonikX/ITMO_ICT_WebDevelopment_2022-2023/pulls?page=2&q=is%3Apr+is%3Aopen', 'https://github.com/TonikX/ITMO_ICT_WebDevelopment_2022-2023/pulls?page=3&q=is%3Apr+is%3Aopen', ]","title":"urls.py"},{"location":"lab2/#connectionpy","text":"import psycopg2 class DB: INSERT_SQL = \"\"\"insert into public.prs(title, date, author) values (%s, %s, %s);\"\"\" @staticmethod def connect(): con = psycopg2.connect( dbname=\"web_tools_db\", user=\"postgres\", password=\"postgres\", host=\"localhost\", port=\"5432\" ) return con","title":"connection.py"},{"location":"lab3/","text":"Lab 3 \u041f\u0440\u0438\u043b\u043e\u0436\u0435\u043d\u0438\u044f \u0431\u044b\u043b\u0438 \u0443\u043f\u0430\u043a\u043e\u0432\u0430\u043d\u044b \u0432 Dockerfile, \u043e\u0431\u044a\u0435\u0434\u0438\u043d\u0435\u043d\u044b \u0432 docker-compose, \u0434\u043e\u0431\u0430\u0432\u043b\u0435\u043d\u0430 \u043e\u0447\u0435\u0440\u0435\u0434\u044c celery \u0441 \u0445\u0440\u0430\u043d\u0438\u043b\u0438\u0449\u0435\u043c redis. \u041a\u043e\u0434 \u0431\u044b\u043b \u043c\u0435\u0441\u0442\u0430\u043c\u0438 \u043f\u0435\u0440\u0435\u0440\u0430\u0431\u043e\u0442\u0430\u043d \u0434\u043b\u044f \u043a\u043e\u0440\u0440\u0435\u043a\u0442\u043d\u043e\u0439 \u0440\u0430\u0431\u043e\u0442\u044b \u043a\u043e\u043d\u0442\u0435\u0439\u043d\u0435\u0440\u0438\u0437\u0430\u0446\u0438\u0438. \u041d\u0430\u0431\u043b\u044e\u0434\u0435\u043d\u0438\u0435 \u0437\u0430 \u043a\u043e\u043d\u0442\u0435\u0439\u043d\u0435\u0440\u0430\u043c\u0438 \u0431\u044b\u043b\u043e \u0447\u0435\u0440\u0435\u0437 Services \u0432\u043d\u0443\u0442\u0440\u0438 PyCharm. \u041f\u0440\u0438\u043b\u043e\u0436\u0435\u043d\u0438\u0435 app - \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442 \u041b\u04201. \u041f\u0440\u0438\u043b\u043e\u0436\u0435\u043d\u0438\u0435 \u0441elery - \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442 \u0440\u0430\u0431\u043e\u0442\u044b \u041b\u04202+\u041b\u04203. \u041d\u0438\u0436\u0435 \u043f\u0440\u0438\u0432\u0435\u0434\u0435\u043d\u044b \u043f\u0435\u0440\u0435\u0440\u0430\u0431\u043e\u0442\u0430\u043d\u043d\u044b\u0435 \u0438 \u043d\u0430\u043f\u0438\u0441\u0430\u043d\u043d\u044b\u0435 \u0444\u0430\u0439\u043b\u044b \u0432 \u0440\u0430\u043c\u043a\u0430\u0445 \u0434\u0430\u043d\u043d\u043e\u0439 \u0440\u0430\u0431\u043e\u0442\u044b. \u041e\u0431\u0449\u0438\u0439 docker-compose.yml version: '3.9' services: celery_app: build: context: ./celery dockerfile: Dockerfile container_name: celery_app restart: unless-stopped ports: - \"8081:8081\" env_file: - .env depends_on: - redis celery_worker: build: context: ./celery env_file: - .env container_name: celery_worker command: celery -A celery_worker worker -l info -E restart: unless-stopped depends_on: - redis - celery_app redis: image: redis:latest container_name: redis ports: - \"6379:6379\" restart: unless-stopped app: build: ./app container_name: app ports: - \"8080:8080\" env_file: - .env depends_on: - db - celery_app links: - \"db:database\" db: image: postgres:latest container_name: db ports: - \"5432:5432\" expose: - \"5432:5432\" environment: POSTGRES_USER: ${DB_USER} POSTGRES_PASSWORD: ${DB_PASS} POSTGRES_DB: ${DB_NAME} volumes: - postgres_data:/var/lib/postgresql/data volumes: postgres_data: App - code && screenshots Dockerfile \u041e\u043f\u0438\u0441\u044b\u0432\u0430\u0435\u043c \u0434\u043e\u043a\u0435\u0440\u0444\u0430\u0439\u043b \u0434\u043b\u044f \u043f\u0440\u0438\u043b\u043e\u0436\u0435\u043d\u0438\u044f \u043f\u043e \u0443\u0447\u0435\u0442\u0443 \u0444\u0438\u043d\u0430\u043d\u0441\u043e\u0432 \u0438\u0437 \u041b\u04201. 1. \u0418\u0437 \u043e\u0431\u0440\u0430\u0437\u0430 python:3.12 \u0441\u0442\u0440\u043e\u0438\u043c \u044d\u0442\u043e\u0442 \u043a\u043e\u043d\u0442\u0435\u0439\u043d\u0435\u0440 2. \u0423\u043a\u0430\u0437\u044b\u0432\u0430\u0435\u043c \u0440\u0430\u0431\u043e\u0447\u0443\u044e \u0434\u0438\u0440\u0435\u043a\u0442\u043e\u0440\u0438\u044e, \u0433\u0434\u0435 \u0431\u0443\u0434\u0443\u0442 \u0438\u0441\u043f\u043e\u043b\u043d\u044f\u0442\u044c\u0441\u044f \u0441\u043b\u0435\u0434\u0443\u044e\u0449\u0438\u0435 \u043a\u043e\u043c\u0430\u043d\u0434\u044b 3. \u041a\u043e\u043f\u0438\u0440\u0443\u0435\u043c \u0437\u0430\u0432\u0438\u0441\u0438\u043c\u043e\u0441\u0442\u0438 4. \u0423\u0441\u0442\u0430\u043d\u0430\u0432\u043b\u0438\u0432\u0430\u0435\u043c \u0438\u0445 5. \u041a\u043e\u043f\u0438\u0440\u0443\u0435\u043c \u043e\u0441\u0442\u0430\u043b\u044c\u043d\u044b\u0435 \u0444\u0430\u0439\u043b\u044b 6. \u041f\u0440\u043e\u043a\u0438\u0434\u044b\u0432\u0430\u0435\u043c \u043d\u0430\u0432\u0435\u0440\u0445 \u043f\u043e\u0440\u0442 8080 7. \u0412\u044b\u043f\u043e\u043b\u043d\u044f\u0435\u043c \u043a\u043e\u043c\u0430\u043d\u0434\u0443 \"uvicorn main:app --host 0.0.0.0 --port 8080\" FROM python:3.12 WORKDIR /app COPY ../requirements.txt /app/requirements.txt RUN pip install -r /app/requirements.txt COPY . /app EXPOSE 8080 CMD [\"uvicorn\", \"main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8080\"] main.py from fastapi import FastAPI import categories import customers import operations import transactions from db import * from contextlib import asynccontextmanager @asynccontextmanager async def lifespan(application: FastAPI): init_db() get_session() yield app = FastAPI(lifespan=lifespan) app.include_router(customers.customerRouter) app.include_router(categories.categoryRouter) app.include_router(operations.operationRouter) app.include_router(transactions.transactionRouter) \u0420\u0430\u0431\u043e\u0447\u0438\u0435 \u0441\u043a\u0440\u0438\u043d\u0448\u043e\u0442\u044b Celery - code && screenshots Dockerfile FROM python:3.12 WORKDIR /app COPY requirements.txt . RUN pip install --no-cache-dir --upgrade -r requirements.txt COPY . . EXPOSE 8081 CMD [\"uvicorn\", \"main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8081\"] main.py from fastapi import FastAPI, BackgroundTasks from pydantic import BaseModel from tasks import parse_and_save_threading from celery_app import celery_app # URLs = [ # 'https://github.com/TonikX/ITMO_ICT_WebDevelopment_tools_2023-2024/pulls?page=1&q=is%3Apr+is%3Aopen', # 'https://github.com/TonikX/ITMO_ICT_WebDevelopment_tools_2023-2024/pulls?page=2&q=is%3Apr+is%3Aopen', # 'https://github.com/TonikX/ITMO_ICT_WebDevelopment_tools_2023-2024/pulls?page=3&q=is%3Apr+is%3Aopen', # 'https://github.com/TonikX/ITMO_ICT_WebDevelopment_2022-2023/pulls?page=1&q=is%3Apr+is%3Aopen', # 'https://github.com/TonikX/ITMO_ICT_WebDevelopment_2022-2023/pulls?page=2&q=is%3Apr+is%3Aopen', # 'https://github.com/TonikX/ITMO_ICT_WebDevelopment_2022-2023/pulls?page=3&q=is%3Apr+is%3Aopen', # ] app = FastAPI() class URL(BaseModel): url: str @app.post(\"/\") async def parse_url(item: URL, background_tasks: BackgroundTasks): background_tasks.add_task(parse_and_save_threading, item.url) celery_app.send_task('tasks.parse_and_save_threading', args=[item.url]) return {\"message\": \"started\"} # https://github.com/TonikX/ITMO_ICT_WebDevelopment_tools_2023-2024/pulls?page=1&q=is%3Apr+is%3Aopen # redis-cli lrange main-queue 0 1000 @app.get(\"/\") async def get(): print(\"get\") return {\"message\": \"got main page\"} tasks.py import requests from bs4 import BeautifulSoup from db import DB from celery_app import celery_app @celery_app.task def parse_and_save_threading(url): con = DB.connect() page = requests.get(url) page.raise_for_status() soup = BeautifulSoup(page.text, 'html.parser') prs = soup.find_all('div', class_='Box-row Box-row--focus-gray p-0 mt-0 js-navigation-item js-issue-row') for pr in prs: title = (pr.find('a', class_='Link--primary v-align-middle no-underline h4 js-navigation-open markdown-title'). text) span_text = pr.find('span', class_='opened-by').text.split() date = span_text[2] + ' ' + span_text[3][:-1] + ' ' + span_text[4] author = span_text[6] with con.cursor() as cursor: cursor.execute(DB.INSERT_SQL, (title, date, author)) con.commit() con.close() celery_app.py import celery celery_app = celery.Celery( \"worker\", broker=\"redis://redis:6379/0\", backend=\"redis://redis:6379/0\", ) celery_app.conf.update( task_serializer='json', accept_content=['json'], result_serializer='json', timezone='UTC', enable_utc=True, task_routes={ \"tasks.parse_and_save_threading\": \"main-queue\", }, ) celery_worker.py from celery_app import celery_app from dotenv import load_dotenv import os if __name__ == '__main__': load_dotenv() redis_url = os.getenv(\"CELERY_REDIS_URL\") celery_app.broker_transport_options = {redis_url} celery_app.start() \u0420\u0430\u0431\u043e\u0447\u0438\u0435 \u0441\u043a\u0440\u0438\u043d\u0448\u043e\u0442\u044b","title":"Lab 3"},{"location":"lab3/#lab-3","text":"\u041f\u0440\u0438\u043b\u043e\u0436\u0435\u043d\u0438\u044f \u0431\u044b\u043b\u0438 \u0443\u043f\u0430\u043a\u043e\u0432\u0430\u043d\u044b \u0432 Dockerfile, \u043e\u0431\u044a\u0435\u0434\u0438\u043d\u0435\u043d\u044b \u0432 docker-compose, \u0434\u043e\u0431\u0430\u0432\u043b\u0435\u043d\u0430 \u043e\u0447\u0435\u0440\u0435\u0434\u044c celery \u0441 \u0445\u0440\u0430\u043d\u0438\u043b\u0438\u0449\u0435\u043c redis. \u041a\u043e\u0434 \u0431\u044b\u043b \u043c\u0435\u0441\u0442\u0430\u043c\u0438 \u043f\u0435\u0440\u0435\u0440\u0430\u0431\u043e\u0442\u0430\u043d \u0434\u043b\u044f \u043a\u043e\u0440\u0440\u0435\u043a\u0442\u043d\u043e\u0439 \u0440\u0430\u0431\u043e\u0442\u044b \u043a\u043e\u043d\u0442\u0435\u0439\u043d\u0435\u0440\u0438\u0437\u0430\u0446\u0438\u0438. \u041d\u0430\u0431\u043b\u044e\u0434\u0435\u043d\u0438\u0435 \u0437\u0430 \u043a\u043e\u043d\u0442\u0435\u0439\u043d\u0435\u0440\u0430\u043c\u0438 \u0431\u044b\u043b\u043e \u0447\u0435\u0440\u0435\u0437 Services \u0432\u043d\u0443\u0442\u0440\u0438 PyCharm. \u041f\u0440\u0438\u043b\u043e\u0436\u0435\u043d\u0438\u0435 app - \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442 \u041b\u04201. \u041f\u0440\u0438\u043b\u043e\u0436\u0435\u043d\u0438\u0435 \u0441elery - \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442 \u0440\u0430\u0431\u043e\u0442\u044b \u041b\u04202+\u041b\u04203. \u041d\u0438\u0436\u0435 \u043f\u0440\u0438\u0432\u0435\u0434\u0435\u043d\u044b \u043f\u0435\u0440\u0435\u0440\u0430\u0431\u043e\u0442\u0430\u043d\u043d\u044b\u0435 \u0438 \u043d\u0430\u043f\u0438\u0441\u0430\u043d\u043d\u044b\u0435 \u0444\u0430\u0439\u043b\u044b \u0432 \u0440\u0430\u043c\u043a\u0430\u0445 \u0434\u0430\u043d\u043d\u043e\u0439 \u0440\u0430\u0431\u043e\u0442\u044b.","title":"Lab 3"},{"location":"lab3/#docker-composeyml","text":"version: '3.9' services: celery_app: build: context: ./celery dockerfile: Dockerfile container_name: celery_app restart: unless-stopped ports: - \"8081:8081\" env_file: - .env depends_on: - redis celery_worker: build: context: ./celery env_file: - .env container_name: celery_worker command: celery -A celery_worker worker -l info -E restart: unless-stopped depends_on: - redis - celery_app redis: image: redis:latest container_name: redis ports: - \"6379:6379\" restart: unless-stopped app: build: ./app container_name: app ports: - \"8080:8080\" env_file: - .env depends_on: - db - celery_app links: - \"db:database\" db: image: postgres:latest container_name: db ports: - \"5432:5432\" expose: - \"5432:5432\" environment: POSTGRES_USER: ${DB_USER} POSTGRES_PASSWORD: ${DB_PASS} POSTGRES_DB: ${DB_NAME} volumes: - postgres_data:/var/lib/postgresql/data volumes: postgres_data:","title":"\u041e\u0431\u0449\u0438\u0439 docker-compose.yml"},{"location":"lab3/#app-code-screenshots","text":"","title":"App - code &amp;&amp; screenshots"},{"location":"lab3/#dockerfile","text":"\u041e\u043f\u0438\u0441\u044b\u0432\u0430\u0435\u043c \u0434\u043e\u043a\u0435\u0440\u0444\u0430\u0439\u043b \u0434\u043b\u044f \u043f\u0440\u0438\u043b\u043e\u0436\u0435\u043d\u0438\u044f \u043f\u043e \u0443\u0447\u0435\u0442\u0443 \u0444\u0438\u043d\u0430\u043d\u0441\u043e\u0432 \u0438\u0437 \u041b\u04201. 1. \u0418\u0437 \u043e\u0431\u0440\u0430\u0437\u0430 python:3.12 \u0441\u0442\u0440\u043e\u0438\u043c \u044d\u0442\u043e\u0442 \u043a\u043e\u043d\u0442\u0435\u0439\u043d\u0435\u0440 2. \u0423\u043a\u0430\u0437\u044b\u0432\u0430\u0435\u043c \u0440\u0430\u0431\u043e\u0447\u0443\u044e \u0434\u0438\u0440\u0435\u043a\u0442\u043e\u0440\u0438\u044e, \u0433\u0434\u0435 \u0431\u0443\u0434\u0443\u0442 \u0438\u0441\u043f\u043e\u043b\u043d\u044f\u0442\u044c\u0441\u044f \u0441\u043b\u0435\u0434\u0443\u044e\u0449\u0438\u0435 \u043a\u043e\u043c\u0430\u043d\u0434\u044b 3. \u041a\u043e\u043f\u0438\u0440\u0443\u0435\u043c \u0437\u0430\u0432\u0438\u0441\u0438\u043c\u043e\u0441\u0442\u0438 4. \u0423\u0441\u0442\u0430\u043d\u0430\u0432\u043b\u0438\u0432\u0430\u0435\u043c \u0438\u0445 5. \u041a\u043e\u043f\u0438\u0440\u0443\u0435\u043c \u043e\u0441\u0442\u0430\u043b\u044c\u043d\u044b\u0435 \u0444\u0430\u0439\u043b\u044b 6. \u041f\u0440\u043e\u043a\u0438\u0434\u044b\u0432\u0430\u0435\u043c \u043d\u0430\u0432\u0435\u0440\u0445 \u043f\u043e\u0440\u0442 8080 7. \u0412\u044b\u043f\u043e\u043b\u043d\u044f\u0435\u043c \u043a\u043e\u043c\u0430\u043d\u0434\u0443 \"uvicorn main:app --host 0.0.0.0 --port 8080\" FROM python:3.12 WORKDIR /app COPY ../requirements.txt /app/requirements.txt RUN pip install -r /app/requirements.txt COPY . /app EXPOSE 8080 CMD [\"uvicorn\", \"main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8080\"]","title":"Dockerfile"},{"location":"lab3/#mainpy","text":"from fastapi import FastAPI import categories import customers import operations import transactions from db import * from contextlib import asynccontextmanager @asynccontextmanager async def lifespan(application: FastAPI): init_db() get_session() yield app = FastAPI(lifespan=lifespan) app.include_router(customers.customerRouter) app.include_router(categories.categoryRouter) app.include_router(operations.operationRouter) app.include_router(transactions.transactionRouter)","title":"main.py"},{"location":"lab3/#_1","text":"","title":"\u0420\u0430\u0431\u043e\u0447\u0438\u0435 \u0441\u043a\u0440\u0438\u043d\u0448\u043e\u0442\u044b"},{"location":"lab3/#celery-code-screenshots","text":"","title":"Celery - code &amp;&amp; screenshots"},{"location":"lab3/#dockerfile_1","text":"FROM python:3.12 WORKDIR /app COPY requirements.txt . RUN pip install --no-cache-dir --upgrade -r requirements.txt COPY . . EXPOSE 8081 CMD [\"uvicorn\", \"main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8081\"]","title":"Dockerfile"},{"location":"lab3/#mainpy_1","text":"from fastapi import FastAPI, BackgroundTasks from pydantic import BaseModel from tasks import parse_and_save_threading from celery_app import celery_app # URLs = [ # 'https://github.com/TonikX/ITMO_ICT_WebDevelopment_tools_2023-2024/pulls?page=1&q=is%3Apr+is%3Aopen', # 'https://github.com/TonikX/ITMO_ICT_WebDevelopment_tools_2023-2024/pulls?page=2&q=is%3Apr+is%3Aopen', # 'https://github.com/TonikX/ITMO_ICT_WebDevelopment_tools_2023-2024/pulls?page=3&q=is%3Apr+is%3Aopen', # 'https://github.com/TonikX/ITMO_ICT_WebDevelopment_2022-2023/pulls?page=1&q=is%3Apr+is%3Aopen', # 'https://github.com/TonikX/ITMO_ICT_WebDevelopment_2022-2023/pulls?page=2&q=is%3Apr+is%3Aopen', # 'https://github.com/TonikX/ITMO_ICT_WebDevelopment_2022-2023/pulls?page=3&q=is%3Apr+is%3Aopen', # ] app = FastAPI() class URL(BaseModel): url: str @app.post(\"/\") async def parse_url(item: URL, background_tasks: BackgroundTasks): background_tasks.add_task(parse_and_save_threading, item.url) celery_app.send_task('tasks.parse_and_save_threading', args=[item.url]) return {\"message\": \"started\"} # https://github.com/TonikX/ITMO_ICT_WebDevelopment_tools_2023-2024/pulls?page=1&q=is%3Apr+is%3Aopen # redis-cli lrange main-queue 0 1000 @app.get(\"/\") async def get(): print(\"get\") return {\"message\": \"got main page\"}","title":"main.py"},{"location":"lab3/#taskspy","text":"import requests from bs4 import BeautifulSoup from db import DB from celery_app import celery_app @celery_app.task def parse_and_save_threading(url): con = DB.connect() page = requests.get(url) page.raise_for_status() soup = BeautifulSoup(page.text, 'html.parser') prs = soup.find_all('div', class_='Box-row Box-row--focus-gray p-0 mt-0 js-navigation-item js-issue-row') for pr in prs: title = (pr.find('a', class_='Link--primary v-align-middle no-underline h4 js-navigation-open markdown-title'). text) span_text = pr.find('span', class_='opened-by').text.split() date = span_text[2] + ' ' + span_text[3][:-1] + ' ' + span_text[4] author = span_text[6] with con.cursor() as cursor: cursor.execute(DB.INSERT_SQL, (title, date, author)) con.commit() con.close()","title":"tasks.py"},{"location":"lab3/#celery_apppy","text":"import celery celery_app = celery.Celery( \"worker\", broker=\"redis://redis:6379/0\", backend=\"redis://redis:6379/0\", ) celery_app.conf.update( task_serializer='json', accept_content=['json'], result_serializer='json', timezone='UTC', enable_utc=True, task_routes={ \"tasks.parse_and_save_threading\": \"main-queue\", }, )","title":"celery_app.py"},{"location":"lab3/#celery_workerpy","text":"from celery_app import celery_app from dotenv import load_dotenv import os if __name__ == '__main__': load_dotenv() redis_url = os.getenv(\"CELERY_REDIS_URL\") celery_app.broker_transport_options = {redis_url} celery_app.start()","title":"celery_worker.py"},{"location":"lab3/#_2","text":"","title":"\u0420\u0430\u0431\u043e\u0447\u0438\u0435 \u0441\u043a\u0440\u0438\u043d\u0448\u043e\u0442\u044b"},{"location":"leetcode/","text":"Leetcode 24.03.2024 - 07.05.2024 = 6 weeks 3sum class Solution: def threeSum(self, nums: List[int]) -> List[List[int]]: res = set() n, p, z = [], [], [] for num in nums: if num > 0: p.append(num) elif num < 0: n.append(num) else: z.append(num) N, P = set(n), set(p) if z: for num in P: if -1*num in N: res.add((-1*num, 0, num)) if len(z) >= 3: res.add((0,0,0)) for i in range(len(n)): for j in range(i+1,len(n)): target = -1*(n[i]+n[j]) if target in P: res.add(tuple(sorted([n[i],n[j],target]))) for i in range(len(p)): for j in range(i+1,len(p)): target = -1*(p[i]+p[j]) if target in N: res.add(tuple(sorted([p[i],p[j],target]))) return res Group Anagrams class Solution: def groupAnagrams(self, strs: List[str]) -> List[List[str]]: result = [] sorted_s = {} i = 0 for s in strs: if not result: sorted_s[''.join(sorted(s))] = i i += 1 result.append([s]) continue for j in range(len(result)): if (''.join(sorted(s))) in sorted_s: result[sorted_s[''.join(sorted(s))]].append(s) break else: sorted_s[''.join(sorted(s))] = i i += 1 result.append([s]) break return result Longest Substring Without Repeating Characters class Solution: def lengthOfLongestSubstring(self, s: str) -> int: n = len(s) maxLength = 0 charIndex = [-1] * 128 left = 0 for right in range(n): if charIndex[ord(s[right])] >= left: left = charIndex[ord(s[right])] + 1 charIndex[ord(s[right])] = right maxLength = max(maxLength, right - left + 1) return maxLength Longest Palindromic Substring class Solution: def longestPalindrome(self, s: str) -> str: if not s: return \"\" def expand_around_center(s: str, left: int, right: int): while left >= 0 and right < len(s) and s[left] == s[right]: left -= 1 right += 1 return right - left - 1 start = 0 end = 0 for i in range(len(s)): odd = expand_around_center(s, i, i) even = expand_around_center(s, i, i + 1) max_len = max(odd, even) if max_len > end - start: start = i - (max_len - 1) // 2 end = i + max_len // 2 return s[start:end+1] Increasing Triplet Subsequence class Solution: def increasingTriplet(self, nums: List[int]) -> bool: first = second = float('inf') for n in nums: if n <= first: first = n elif n <= second: second = n else: return True return False Set Matrix Zeroes class Solution: def setZeroes(self, matrix: List[List[int]]) -> None: m = len(matrix) n = len(matrix[0]) shouldFillFirstRow = 0 in matrix[0] shouldFillFirstCol = 0 in list(zip(*matrix))[0] for i in range(1, m): for j in range(1, n): if matrix[i][j] == 0: matrix[i][0] = 0 matrix[0][j] = 0 for i in range(1, m): for j in range(1, n): if matrix[i][0] == 0 or matrix[0][j] == 0: matrix[i][j] = 0 if shouldFillFirstRow: matrix[0] = [0] * n if shouldFillFirstCol: for row in matrix: row[0] = 0","title":"Leetcode"},{"location":"leetcode/#leetcode","text":"24.03.2024 - 07.05.2024 = 6 weeks","title":"Leetcode"},{"location":"leetcode/#3sum","text":"class Solution: def threeSum(self, nums: List[int]) -> List[List[int]]: res = set() n, p, z = [], [], [] for num in nums: if num > 0: p.append(num) elif num < 0: n.append(num) else: z.append(num) N, P = set(n), set(p) if z: for num in P: if -1*num in N: res.add((-1*num, 0, num)) if len(z) >= 3: res.add((0,0,0)) for i in range(len(n)): for j in range(i+1,len(n)): target = -1*(n[i]+n[j]) if target in P: res.add(tuple(sorted([n[i],n[j],target]))) for i in range(len(p)): for j in range(i+1,len(p)): target = -1*(p[i]+p[j]) if target in N: res.add(tuple(sorted([p[i],p[j],target]))) return res","title":"3sum"},{"location":"leetcode/#group-anagrams","text":"class Solution: def groupAnagrams(self, strs: List[str]) -> List[List[str]]: result = [] sorted_s = {} i = 0 for s in strs: if not result: sorted_s[''.join(sorted(s))] = i i += 1 result.append([s]) continue for j in range(len(result)): if (''.join(sorted(s))) in sorted_s: result[sorted_s[''.join(sorted(s))]].append(s) break else: sorted_s[''.join(sorted(s))] = i i += 1 result.append([s]) break return result","title":"Group Anagrams"},{"location":"leetcode/#longest-substring-without-repeating-characters","text":"class Solution: def lengthOfLongestSubstring(self, s: str) -> int: n = len(s) maxLength = 0 charIndex = [-1] * 128 left = 0 for right in range(n): if charIndex[ord(s[right])] >= left: left = charIndex[ord(s[right])] + 1 charIndex[ord(s[right])] = right maxLength = max(maxLength, right - left + 1) return maxLength","title":"Longest Substring Without Repeating Characters"},{"location":"leetcode/#longest-palindromic-substring","text":"class Solution: def longestPalindrome(self, s: str) -> str: if not s: return \"\" def expand_around_center(s: str, left: int, right: int): while left >= 0 and right < len(s) and s[left] == s[right]: left -= 1 right += 1 return right - left - 1 start = 0 end = 0 for i in range(len(s)): odd = expand_around_center(s, i, i) even = expand_around_center(s, i, i + 1) max_len = max(odd, even) if max_len > end - start: start = i - (max_len - 1) // 2 end = i + max_len // 2 return s[start:end+1]","title":"Longest Palindromic Substring"},{"location":"leetcode/#increasing-triplet-subsequence","text":"class Solution: def increasingTriplet(self, nums: List[int]) -> bool: first = second = float('inf') for n in nums: if n <= first: first = n elif n <= second: second = n else: return True return False","title":"Increasing Triplet Subsequence"},{"location":"leetcode/#set-matrix-zeroes","text":"class Solution: def setZeroes(self, matrix: List[List[int]]) -> None: m = len(matrix) n = len(matrix[0]) shouldFillFirstRow = 0 in matrix[0] shouldFillFirstCol = 0 in list(zip(*matrix))[0] for i in range(1, m): for j in range(1, n): if matrix[i][j] == 0: matrix[i][0] = 0 matrix[0][j] = 0 for i in range(1, m): for j in range(1, n): if matrix[i][0] == 0 or matrix[0][j] == 0: matrix[i][j] = 0 if shouldFillFirstRow: matrix[0] = [0] * n if shouldFillFirstCol: for row in matrix: row[0] = 0","title":"Set Matrix Zeroes"},{"location":"leetcode2/","text":"Leetcode 13.05.2024 - 24.05.2024 = 2 weeks 1 more for extra point Count and Say class Solution: def countAndSay(self, n: int) -> str: def count_til_diff(s: str): res = '' i = 0 temp = '' while i < len(s): count = 1 check = s[i] if (check == temp): break temp = check for j in range(i + 1, len(s)): if s[j] != check: i = j break count += 1 if j == len(s) - 1: i = j break res += str(count) + check return res if n == 1: return '1' return count_til_diff(self.countAndSay(n - 1)) Add Two Numbers # Definition for singly-linked list. # class ListNode: # def __init__(self, val=0, next=None): # self.val = val # self.next = next class Solution: def addTwoNumbers(self, l1: Optional[ListNode], l2: Optional[ListNode]) -> Optional[ListNode]: dummy = ListNode() res = dummy total = carry = 0 while l1 or l2 or carry: total = carry if l1: total += l1.val l1 = l1.next if l2: total += l2.val l2 = l2.next num = total % 10 carry = total // 10 dummy.next = ListNode(num) dummy = dummy.next return res.next Odd Even Linked List # Definition for singly-linked list. # class ListNode: # def __init__(self, val=0, next=None): # self.val = val # self.next = next class Solution: def oddEvenList(self, head: Optional[ListNode]) -> Optional[ListNode]: if head == None or head.next == None : return head odd = ListNode(0) odd_ptr = odd even = ListNode(0) even_ptr = even idx = 1 while head != None : if idx % 2 == 0: even_ptr.next = head even_ptr = even_ptr.next else: odd_ptr.next = head odd_ptr = odd_ptr.next head = head.next idx+=1 even_ptr.next = None odd_ptr.next = even.next return odd.next","title":"Leetcode"},{"location":"leetcode2/#leetcode","text":"13.05.2024 - 24.05.2024 = 2 weeks 1 more for extra point","title":"Leetcode"},{"location":"leetcode2/#count-and-say","text":"class Solution: def countAndSay(self, n: int) -> str: def count_til_diff(s: str): res = '' i = 0 temp = '' while i < len(s): count = 1 check = s[i] if (check == temp): break temp = check for j in range(i + 1, len(s)): if s[j] != check: i = j break count += 1 if j == len(s) - 1: i = j break res += str(count) + check return res if n == 1: return '1' return count_til_diff(self.countAndSay(n - 1))","title":"Count and Say"},{"location":"leetcode2/#add-two-numbers","text":"# Definition for singly-linked list. # class ListNode: # def __init__(self, val=0, next=None): # self.val = val # self.next = next class Solution: def addTwoNumbers(self, l1: Optional[ListNode], l2: Optional[ListNode]) -> Optional[ListNode]: dummy = ListNode() res = dummy total = carry = 0 while l1 or l2 or carry: total = carry if l1: total += l1.val l1 = l1.next if l2: total += l2.val l2 = l2.next num = total % 10 carry = total // 10 dummy.next = ListNode(num) dummy = dummy.next return res.next","title":"Add Two Numbers"},{"location":"leetcode2/#odd-even-linked-list","text":"# Definition for singly-linked list. # class ListNode: # def __init__(self, val=0, next=None): # self.val = val # self.next = next class Solution: def oddEvenList(self, head: Optional[ListNode]) -> Optional[ListNode]: if head == None or head.next == None : return head odd = ListNode(0) odd_ptr = odd even = ListNode(0) even_ptr = even idx = 1 while head != None : if idx % 2 == 0: even_ptr.next = head even_ptr = even_ptr.next else: odd_ptr.next = head odd_ptr = odd_ptr.next head = head.next idx+=1 even_ptr.next = None odd_ptr.next = even.next return odd.next","title":"Odd Even Linked List"}]}